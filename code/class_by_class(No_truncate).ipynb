{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this file, we just repeat what we did in class_by_class.ipynb file multiple times to discover a more robust correlation between the entropy difference (of a subsample and its class) and the corresponding train/test set accuracy. However, we decide not to truncate the singular vector of the feature space and get BSIE value directly from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import tarfile\n",
    "from torchvision.datasets.utils import download_url\n",
    "from torch.utils.data import random_split, DataLoader, SubsetRandomSampler, Subset, ConcatDataset\n",
    "import os\n",
    "from Truncate import truncate\n",
    "from BSI_Entropy import BSIE\n",
    "import numpy as np\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import ToTensor\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We first load in the Cifar-10 images and have all the classes/functions set up like before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './data/cifar10'\n",
    "training_dataset = ImageFolder(data_dir+'/train', transform=ToTensor())\n",
    "test_dataset = ImageFolder(data_dir+'/test', transform=ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "    \n",
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "class DeviceDataLoader():\n",
    "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dl: \n",
    "            yield to_device(b, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches\"\"\"\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ImageClassificationBase(nn.Module):\n",
    "    def training_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)                  # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)                    # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels)   # Calculate loss\n",
    "        acc = accuracy(out, labels)           # Calculate accuracy\n",
    "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
    "            epoch, result['train_loss'], result['val_loss'], result['val_acc']))\n",
    "        \n",
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, val_loader):\n",
    "    model.eval()\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
    "    return model.validation_epoch_end(outputs)\n",
    "\n",
    "def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n",
    "    history = []\n",
    "    optimizer = opt_func(model.parameters(), lr)\n",
    "    for epoch in range(epochs):\n",
    "        # Training Phase \n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        for batch in train_loader:\n",
    "            loss = model.training_step(batch)\n",
    "            train_losses.append(loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        # Validation phase\n",
    "        result = evaluate(model, val_loader)\n",
    "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
    "        model.epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cifar10CnnModel(ImageClassificationBase):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2), # output: 64 x 16 x 16\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2), # output: 128 x 8 x 8\n",
    "\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2), # output: 256 x 4 x 4\n",
    "\n",
    "            nn.Flatten(), \n",
    "            nn.Linear(256*4*4, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 10))\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        return self.network(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = get_default_device()\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we create a model object from the class and assign it trained parameters we saved before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelCNN = to_device(Cifar10CnnModel(), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelCNN.load_state_dict(torch.load('cifar10-cnn.pth')) # load our pretrained model parameters and assign to the new model object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 10000)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_dataset), len(test_dataset) # make sure the number of images/labels in train and test set are correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.9372484087944031, 'val_acc': 0.7689453363418579}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data.dataloader import DataLoader\n",
    "batch_size=128\n",
    "test_loader = DeviceDataLoader(DataLoader(test_dataset, batch_size*2), device)\n",
    "evaluate(modelCNN, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This following function helps us to attain intermediate feature in our embedding function which is the CNN we just created using the parameters we load in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = {}\n",
    "def get_features(name):\n",
    "    def hook(model, input, output):\n",
    "        features[name] = output.detach()\n",
    "\n",
    "    return hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.hooks.RemovableHandle at 0x22152648910>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelCNN.network[18].register_forward_hook(get_features('18'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In the following code, we attain the intermediate feature space for each class in the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_feature_data = {label: [] for label in range(10)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, label in training_dataset:\n",
    "    if label in class_feature_data:\n",
    "        output = modelCNN(to_device(image.unsqueeze(0), device))\n",
    "        class_feature_data[label].append(features['18'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in class_feature_data:\n",
    "    class_feature_data[label] = torch.cat(class_feature_data[label], dim = 0).T "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We then apply SVD to the feature space of each training class to attain singular vector. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: tensor([8305.8789, 1585.3182, 1073.5406,  963.0099,  828.8642,  769.5621,\n",
      "         616.4266,  580.3412,  516.1616,  488.6954,  402.4275,  341.2084,\n",
      "         275.5750,  266.5753,  257.8827,  231.7271,  198.1219,  183.4829,\n",
      "         180.9243,  177.5941,  156.9813,  144.6703,  141.9810,  132.6933,\n",
      "         126.5861,  122.6644,  117.9465,  113.8699,  110.0822,  106.3363,\n",
      "         103.7124,   93.6782,   91.7617,   89.5256,   84.1956,   82.4179,\n",
      "          80.3859,   78.2227,   75.4202,   72.8308,   71.0707,   69.9203,\n",
      "          65.3629,   64.8393,   62.6921,   60.4378,   58.1620,   56.9152,\n",
      "          54.7706,   54.1711,   52.7214,   51.6815,   50.4430,   49.4335,\n",
      "          47.0124,   45.7740,   43.8802,   43.6093,   42.2480,   40.5315,\n",
      "          39.1501,   37.6497,   36.0807,   34.7374]), 1: tensor([12095.2061,  1403.4337,  1103.4655,   963.6672,   940.5552,   853.0527,\n",
      "          744.2352,   670.6514,   567.7023,   496.4117,   435.3126,   407.3419,\n",
      "          350.2057,   277.2058,   250.3987,   228.0301,   213.1301,   201.9636,\n",
      "          183.1754,   177.0799,   173.2148,   157.2500,   154.9059,   141.8093,\n",
      "          136.7393,   130.5036,   123.9009,   111.7951,   109.5792,   104.0679,\n",
      "          102.0208,    98.5726,    95.6230,    92.5422,    91.4762,    87.7978,\n",
      "           85.6393,    80.0061,    75.8346,    74.1482,    72.9685,    70.6738,\n",
      "           68.0645,    67.4477,    63.2545,    62.6573,    58.7270,    57.1137,\n",
      "           55.9109,    54.9257,    53.4217,    51.6753,    50.8225,    49.1771,\n",
      "           46.7251,    46.5821,    44.0645,    43.7546,    42.5789,    39.9152,\n",
      "           38.9562,    36.2970,    35.4175,    31.8563]), 2: tensor([6268.6768,  996.6603,  861.0262,  768.5312,  739.1451,  694.6696,\n",
      "         600.1634,  527.4907,  457.0351,  414.4943,  364.2594,  286.4704,\n",
      "         252.5366,  232.2138,  215.6590,  201.4022,  193.2244,  170.9879,\n",
      "         168.6637,  152.4425,  139.6423,  135.0280,  128.0127,  120.3685,\n",
      "         113.6636,  107.9870,  103.6013,  101.6421,   95.3172,   93.9559,\n",
      "          88.8051,   85.6524,   82.2905,   80.0169,   76.2634,   74.8454,\n",
      "          73.6839,   72.4649,   67.7688,   66.6625,   64.4223,   61.4686,\n",
      "          60.3447,   58.9813,   57.0994,   55.9028,   54.6610,   53.0541,\n",
      "          49.8968,   48.1705,   46.9777,   46.7670,   45.8985,   43.3955,\n",
      "          42.3475,   41.3480,   40.6217,   39.2341,   37.1279,   36.3377,\n",
      "          35.2792,   34.6068,   33.2892,   31.7638]), 3: tensor([6473.5073,  841.2786,  778.4031,  699.7131,  636.0625,  580.7430,\n",
      "         545.3973,  478.3984,  441.1371,  360.8887,  271.3305,  227.0016,\n",
      "         215.7848,  210.0773,  184.9863,  174.0165,  161.9877,  152.2511,\n",
      "         149.6021,  136.9679,  129.8981,  125.9189,  120.4214,  109.9679,\n",
      "         104.4016,  103.5947,   97.8948,   96.5096,   85.8014,   85.5063,\n",
      "          82.8391,   81.4511,   78.8962,   73.4542,   70.5081,   69.6882,\n",
      "          66.7658,   64.2578,   64.0274,   62.4119,   60.9270,   60.1115,\n",
      "          58.6312,   55.4811,   53.9831,   52.1251,   51.3327,   50.8141,\n",
      "          47.4976,   47.1265,   45.3364,   43.8578,   43.6088,   43.3220,\n",
      "          41.2991,   39.3377,   38.7576,   37.6581,   36.6142,   35.8798,\n",
      "          34.7457,   33.8410,   33.0287,   31.0110]), 4: tensor([7251.3999, 1030.9064,  909.2327,  707.2688,  637.4417,  578.5201,\n",
      "         508.1140,  466.0776,  446.0780,  397.8710,  320.4633,  269.8743,\n",
      "         264.0945,  229.7420,  226.3317,  194.3986,  188.6454,  166.8791,\n",
      "         154.9358,  152.1550,  140.9037,  124.5961,  121.1879,  118.2018,\n",
      "         111.4068,   99.5754,   99.0052,   96.0552,   93.1947,   88.4500,\n",
      "          83.6878,   81.2279,   77.7753,   77.0465,   75.4441,   72.9830,\n",
      "          69.8479,   68.6878,   66.5030,   65.3280,   62.9284,   60.9607,\n",
      "          57.7178,   55.7312,   55.0482,   51.6707,   50.9145,   48.9035,\n",
      "          48.0556,   47.2219,   46.6511,   44.7408,   42.6484,   41.6211,\n",
      "          40.9727,   39.4311,   38.1823,   37.1305,   35.6565,   34.5898,\n",
      "          33.4765,   32.3365,   31.2384,   30.4821]), 5: tensor([6615.5000,  935.8938,  749.0901,  681.4392,  659.0427,  591.3130,\n",
      "         568.2397,  471.9457,  434.5263,  397.9953,  320.4688,  229.8735,\n",
      "         207.7418,  199.3160,  181.2436,  179.3377,  164.5392,  158.5162,\n",
      "         144.6888,  135.9444,  125.6181,  122.4719,  114.7564,  108.4020,\n",
      "          98.2476,   96.3082,   94.3113,   87.3923,   86.2062,   83.2604,\n",
      "          80.6292,   78.4679,   76.5878,   72.7462,   71.2571,   69.3191,\n",
      "          67.5854,   64.7256,   61.7663,   59.2221,   57.9550,   57.0776,\n",
      "          55.5528,   53.5544,   52.0715,   51.1490,   49.4429,   48.2574,\n",
      "          47.1759,   45.2133,   44.9031,   42.5675,   41.7146,   40.3162,\n",
      "          39.2917,   38.8730,   38.4060,   36.5054,   34.4352,   33.8537,\n",
      "          32.6440,   32.3013,   31.1622,   29.4608]), 6: tensor([7264.2148, 1025.9622,  821.9323,  766.3347,  668.6025,  559.7619,\n",
      "         490.6772,  444.9507,  408.4172,  347.1433,  305.5564,  228.6729,\n",
      "         222.3128,  206.2740,  182.9453,  170.8316,  157.5761,  153.2848,\n",
      "         131.4534,  127.3159,  126.6383,  111.9518,  103.7711,  100.5675,\n",
      "          94.8066,   89.5136,   87.9663,   82.4812,   80.3807,   75.5823,\n",
      "          75.0115,   72.9168,   70.3978,   67.0040,   66.0912,   62.3881,\n",
      "          61.8958,   60.0585,   58.2270,   55.7178,   53.8061,   52.5783,\n",
      "          49.9245,   48.5092,   48.1664,   46.0542,   45.5001,   43.5996,\n",
      "          41.0822,   40.6236,   39.1936,   38.3900,   36.9234,   36.2563,\n",
      "          35.1064,   34.7974,   33.9532,   31.8801,   31.6158,   30.7459,\n",
      "          29.4570,   27.8902,   26.1976,   25.0586]), 7: tensor([9169.8828, 1493.6215, 1051.6710,  827.7892,  704.5131,  648.9139,\n",
      "         604.9308,  552.1254,  529.1401,  405.0483,  379.9564,  326.4211,\n",
      "         275.0515,  241.4179,  225.5518,  223.2711,  190.9410,  185.7654,\n",
      "         180.1633,  159.7839,  149.9531,  140.9736,  129.3146,  123.8428,\n",
      "         118.9251,  117.3516,  110.0507,  101.6755,  100.0895,   94.0084,\n",
      "          89.3221,   87.6476,   83.3122,   83.0177,   79.0291,   77.2495,\n",
      "          76.2627,   75.2523,   72.6804,   71.6437,   68.6938,   65.9932,\n",
      "          62.9971,   61.2922,   59.8471,   58.7325,   57.2511,   55.7114,\n",
      "          54.3630,   52.0995,   49.9387,   48.9176,   47.1538,   46.9003,\n",
      "          44.8975,   43.6781,   41.0143,   40.4583,   40.1294,   39.0184,\n",
      "          37.9315,   34.9119,   34.0490,   32.1201]), 8: tensor([9594.4805, 1124.0610, 1052.3362, 1004.5804,  869.7374,  671.5615,\n",
      "         621.2519,  523.7562,  475.3379,  443.6017,  403.6830,  317.1657,\n",
      "         286.7527,  249.1192,  224.5342,  216.5424,  185.4713,  184.0177,\n",
      "         174.7412,  168.6416,  144.3980,  139.9327,  130.4194,  128.2969,\n",
      "         119.3904,  116.7353,  110.4874,  104.6957,  102.1369,  100.8237,\n",
      "          93.3471,   87.9545,   87.0240,   81.4927,   76.3620,   74.8747,\n",
      "          72.8455,   72.1757,   69.9687,   67.7925,   63.9059,   63.6517,\n",
      "          61.2246,   57.5016,   57.1501,   54.6067,   54.3347,   52.6592,\n",
      "          51.7210,   50.4249,   48.6767,   46.9900,   45.1177,   43.7656,\n",
      "          41.3862,   39.9052,   39.1436,   38.6954,   36.9722,   35.7993,\n",
      "          34.9810,   33.8001,   32.5454,   30.0804]), 9: tensor([10423.7295,  1075.6924,  1005.2132,   868.2537,   845.2270,   768.0860,\n",
      "          653.5539,   533.2513,   448.2159,   377.9797,   349.4870,   321.1977,\n",
      "          258.0855,   248.5007,   222.5318,   209.2140,   185.0927,   176.9587,\n",
      "          170.2491,   150.6953,   141.7572,   133.9512,   126.0533,   120.6464,\n",
      "          114.3579,   106.9467,   101.3006,   100.5582,    96.6379,    94.3995,\n",
      "           91.8883,    90.4309,    87.2283,    83.8863,    80.6998,    77.5528,\n",
      "           76.5992,    75.3139,    74.1166,    70.6445,    68.6330,    63.5477,\n",
      "           61.1679,    60.1646,    56.9889,    55.9821,    54.9749,    54.2968,\n",
      "           52.9092,    51.9405,    50.1667,    48.8075,    46.8235,    46.0916,\n",
      "           45.4860,    44.6703,    41.4841,    40.2458,    37.5727,    36.9767,\n",
      "           36.2387,    35.1060,    33.5660,    30.2874])}\n"
     ]
    }
   ],
   "source": [
    "singular_vector = {label: torch.svd(class_feature_data[label])[1] for label in class_feature_data}\n",
    "print(singular_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note here, we don't truncate singular vector anymore to get BSIE value because the singular vector of each training class feature space contains values apparently greater than 0 almost at each entry. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.06290901692797712, 1: 0.06283993894178475, 2: 0.06495570296841247, 3: 0.06314928805309994, 4: 0.06271682050760996, 5: 0.06349178769941977, 6: 0.06271585297092763, 7: 0.062195439924848994, 8: 0.06215472324653093, 9: 0.0626122551072612}\n"
     ]
    }
   ],
   "source": [
    "entropy = {label: BSIE(singular_vector[label]).item() for label in singular_vector}\n",
    "print(entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, we also want to test the performance of the original CNN model we trained with all our Cifar-10 training dataset(the embedding function) on the test set of each class and training set of each class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = {0: (0, 5000), 1:(5000, 10000), 2:(10000, 15000), 3:(15000, 20000), 4:(20000, 25000), 5:(25000, 30000), 6:(30000, 35000), 7:(35000, 40000), 8:(40000, 45000), 9:(45000, 50000)}\n",
    "training_data_by_class = {category: Subset(ImageFolder('./data/cifar10/train/', transform=ToTensor()), range(classes[category][0], classes[category][1])) for category in classes}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.9573644399642944, 1: 0.958903968334198, 2: 0.9373161196708679, 3: 0.9092830419540405, 4: 0.9389591217041016, 5: 0.8896943926811218, 6: 0.9713580012321472, 7: 0.961638331413269, 8: 0.9748736619949341, 9: 0.9779986143112183}\n"
     ]
    }
   ],
   "source": [
    "train_accu_by_class = {label: evaluate(modelCNN, DeviceDataLoader(DataLoader(training_data_by_class[label], batch_size*2), device))['val_acc'] for label in range(10)}\n",
    "print(train_accu_by_class)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Above is the original CNN model's performance on the training data of each class. We will also test its performance on the test set of each class below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_classes = {0: (0, 1000), 1:(1000, 2000), 2:(2000, 3000), 3:(3000, 4000), 4:(4000, 5000), 5:(5000, 6000), 6:(6000, 7000), 7:(7000, 8000), 8:(8000, 9000), 9:(9000, 10000)}\n",
    "test_data_by_class = {category: Subset(ImageFolder('./data/cifar10/test/', transform=ToTensor()), range(test_classes[category][0], test_classes[category][1])) for category in test_classes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.8268453478813171, 1: 0.8339170217514038, 2: 0.6760169863700867, 3: 0.5890355706214905, 4: 0.711274266242981, 5: 0.6273572444915771, 6: 0.8606209754943848, 7: 0.8032732009887695, 8: 0.8591729402542114, 9: 0.8756734728813171}\n"
     ]
    }
   ],
   "source": [
    "test_accu_by_class = {label: evaluate(modelCNN, DeviceDataLoader(DataLoader(test_data_by_class[label], batch_size*2), device))['val_acc'] for label in range(10)}\n",
    "print(test_accu_by_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def select_subsample(classified_training_data, n_sample = 500): \n",
    "    subsample = {i: random_split(classified_training_data[i], [n_sample, len(classified_training_data[i]) - n_sample])[0] for i in classified_training_data}\n",
    "    return subsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 42\n",
    "torch.manual_seed(random_seed);\n",
    "\n",
    "    \n",
    "val_size = 5000\n",
    "train_size = len(training_dataset) - val_size\n",
    "\n",
    "train_ds, val_ds = random_split(training_dataset, [train_size, val_size])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 15\n",
    "opt_func = torch.optim.Adam\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], train_loss: 2.2793, val_loss: 2.2826, val_acc: 0.1891\n",
      "Epoch [1], train_loss: 2.0833, val_loss: 2.0292, val_acc: 0.2501\n",
      "Epoch [2], train_loss: 1.9772, val_loss: 1.9202, val_acc: 0.2910\n",
      "Epoch [3], train_loss: 1.8858, val_loss: 1.8891, val_acc: 0.3022\n",
      "Epoch [4], train_loss: 1.8110, val_loss: 1.7992, val_acc: 0.3504\n",
      "Epoch [5], train_loss: 1.7019, val_loss: 1.7757, val_acc: 0.3452\n",
      "Epoch [6], train_loss: 1.6241, val_loss: 1.6574, val_acc: 0.3906\n",
      "Epoch [7], train_loss: 1.5477, val_loss: 1.7318, val_acc: 0.3777\n",
      "Epoch [8], train_loss: 1.4906, val_loss: 1.6906, val_acc: 0.3928\n",
      "Epoch [9], train_loss: 1.4331, val_loss: 1.6168, val_acc: 0.4066\n",
      "Epoch [10], train_loss: 1.3606, val_loss: 1.5777, val_acc: 0.4470\n",
      "Epoch [11], train_loss: 1.3211, val_loss: 1.6990, val_acc: 0.4171\n",
      "Epoch [12], train_loss: 1.2683, val_loss: 1.5414, val_acc: 0.4448\n",
      "Epoch [13], train_loss: 1.1922, val_loss: 1.5715, val_acc: 0.4465\n",
      "Epoch [14], train_loss: 1.0944, val_loss: 1.5704, val_acc: 0.4676\n",
      "   class  Test_Accuracy  Entropy_difference\n",
      "0      0       0.622610            0.014078\n",
      "1      1       0.707192            0.002114\n",
      "2      2       0.358421            0.007086\n",
      "3      3       0.525460            0.006590\n",
      "4      4       0.253148            0.020114\n",
      "5      5       0.257250            0.017768\n",
      "6      6       0.598104            0.029339\n",
      "7      7       0.453585            0.030361\n",
      "8      8       0.468830            0.004933\n",
      "9      9       0.494646            0.003825\n",
      "Epoch [0], train_loss: 2.2962, val_loss: 2.2242, val_acc: 0.1447\n",
      "Epoch [1], train_loss: 2.0923, val_loss: 2.2479, val_acc: 0.1942\n",
      "Epoch [2], train_loss: 2.0170, val_loss: 2.0276, val_acc: 0.2490\n",
      "Epoch [3], train_loss: 1.8864, val_loss: 1.9094, val_acc: 0.2804\n",
      "Epoch [4], train_loss: 1.7962, val_loss: 1.7860, val_acc: 0.3298\n",
      "Epoch [5], train_loss: 1.7403, val_loss: 1.7312, val_acc: 0.3471\n",
      "Epoch [6], train_loss: 1.6900, val_loss: 1.8087, val_acc: 0.3237\n",
      "Epoch [7], train_loss: 1.6739, val_loss: 1.6997, val_acc: 0.3639\n",
      "Epoch [8], train_loss: 1.5869, val_loss: 1.6036, val_acc: 0.4129\n",
      "Epoch [9], train_loss: 1.5142, val_loss: 1.5136, val_acc: 0.4369\n",
      "Epoch [10], train_loss: 1.4218, val_loss: 1.5826, val_acc: 0.4339\n",
      "Epoch [11], train_loss: 1.3943, val_loss: 1.4320, val_acc: 0.4703\n",
      "Epoch [12], train_loss: 1.2981, val_loss: 1.4383, val_acc: 0.4740\n",
      "Epoch [13], train_loss: 1.2347, val_loss: 1.4161, val_acc: 0.5019\n",
      "Epoch [14], train_loss: 1.1516, val_loss: 1.3716, val_acc: 0.5194\n",
      "   class  Test_Accuracy  Entropy_difference\n",
      "0      0       0.377125            0.003914\n",
      "1      1       0.723265            0.007972\n",
      "2      2       0.374265            0.034306\n",
      "3      3       0.375816            0.019846\n",
      "4      4       0.408054            0.039160\n",
      "5      5       0.275712            0.007812\n",
      "6      6       0.644301            0.017609\n",
      "7      7       0.589936            0.006099\n",
      "8      8       0.736822            0.015721\n",
      "9      9       0.639947            0.006187\n",
      "Epoch [0], train_loss: 2.2951, val_loss: 2.2354, val_acc: 0.1774\n",
      "Epoch [1], train_loss: 2.1069, val_loss: 2.1938, val_acc: 0.1918\n",
      "Epoch [2], train_loss: 2.0511, val_loss: 1.9533, val_acc: 0.2978\n",
      "Epoch [3], train_loss: 1.8682, val_loss: 1.8002, val_acc: 0.3312\n",
      "Epoch [4], train_loss: 1.7506, val_loss: 1.8050, val_acc: 0.3252\n",
      "Epoch [5], train_loss: 1.6747, val_loss: 1.6134, val_acc: 0.4100\n",
      "Epoch [6], train_loss: 1.5900, val_loss: 1.6368, val_acc: 0.3951\n",
      "Epoch [7], train_loss: 1.4876, val_loss: 1.5613, val_acc: 0.4263\n",
      "Epoch [8], train_loss: 1.3879, val_loss: 1.5072, val_acc: 0.4520\n",
      "Epoch [9], train_loss: 1.2904, val_loss: 1.5088, val_acc: 0.4698\n",
      "Epoch [10], train_loss: 1.2135, val_loss: 1.4811, val_acc: 0.4662\n",
      "Epoch [11], train_loss: 1.1103, val_loss: 1.5037, val_acc: 0.4864\n",
      "Epoch [12], train_loss: 0.9823, val_loss: 1.4967, val_acc: 0.5046\n",
      "Epoch [13], train_loss: 0.8518, val_loss: 1.6442, val_acc: 0.4727\n",
      "Epoch [14], train_loss: 0.8201, val_loss: 1.6675, val_acc: 0.5065\n",
      "   class  Test_Accuracy  Entropy_difference\n",
      "0      0       0.495416            0.006013\n",
      "1      1       0.568222            0.001799\n",
      "2      2       0.327148            0.008930\n",
      "3      3       0.500885            0.008937\n",
      "4      4       0.337098            0.020269\n",
      "5      5       0.478780            0.009062\n",
      "6      6       0.565499            0.011304\n",
      "7      7       0.487362            0.010223\n",
      "8      8       0.657468            0.003217\n",
      "9      9       0.713281            0.004219\n",
      "Epoch [0], train_loss: 2.3038, val_loss: 2.2867, val_acc: 0.1193\n",
      "Epoch [1], train_loss: 2.1690, val_loss: 2.0369, val_acc: 0.2476\n",
      "Epoch [2], train_loss: 1.9057, val_loss: 1.8081, val_acc: 0.3097\n",
      "Epoch [3], train_loss: 1.7573, val_loss: 1.6878, val_acc: 0.3648\n",
      "Epoch [4], train_loss: 1.6615, val_loss: 1.8923, val_acc: 0.3277\n",
      "Epoch [5], train_loss: 1.5795, val_loss: 1.6187, val_acc: 0.3966\n",
      "Epoch [6], train_loss: 1.5229, val_loss: 1.5097, val_acc: 0.4359\n",
      "Epoch [7], train_loss: 1.4665, val_loss: 1.5002, val_acc: 0.4422\n",
      "Epoch [8], train_loss: 1.4092, val_loss: 1.4927, val_acc: 0.4542\n",
      "Epoch [9], train_loss: 1.3515, val_loss: 1.5249, val_acc: 0.4479\n",
      "Epoch [10], train_loss: 1.3363, val_loss: 1.4621, val_acc: 0.4813\n",
      "Epoch [11], train_loss: 1.2881, val_loss: 1.4293, val_acc: 0.4849\n",
      "Epoch [12], train_loss: 1.2517, val_loss: 1.4847, val_acc: 0.4641\n",
      "Epoch [13], train_loss: 1.1521, val_loss: 1.3902, val_acc: 0.4938\n",
      "Epoch [14], train_loss: 1.0860, val_loss: 1.4198, val_acc: 0.4932\n",
      "   class  Test_Accuracy  Entropy_difference\n",
      "0      0       0.671358            0.004378\n",
      "1      1       0.642681            0.015472\n",
      "2      2       0.439729            0.018403\n",
      "3      3       0.389717            0.022417\n",
      "4      4       0.381078            0.019922\n",
      "5      5       0.469669            0.025808\n",
      "6      6       0.440453            0.003830\n",
      "7      7       0.582801            0.014037\n",
      "8      8       0.698426            0.011681\n",
      "9      9       0.269336            0.003637\n",
      "Epoch [0], train_loss: 2.2057, val_loss: 2.1419, val_acc: 0.2097\n",
      "Epoch [1], train_loss: 2.0220, val_loss: 2.0155, val_acc: 0.2413\n",
      "Epoch [2], train_loss: 1.9466, val_loss: 1.9416, val_acc: 0.3030\n",
      "Epoch [3], train_loss: 1.8720, val_loss: 1.8320, val_acc: 0.3072\n",
      "Epoch [4], train_loss: 1.7749, val_loss: 1.8042, val_acc: 0.3347\n",
      "Epoch [5], train_loss: 1.6966, val_loss: 1.8176, val_acc: 0.3405\n",
      "Epoch [6], train_loss: 1.6232, val_loss: 1.6935, val_acc: 0.3934\n",
      "Epoch [7], train_loss: 1.5731, val_loss: 1.5849, val_acc: 0.4283\n",
      "Epoch [8], train_loss: 1.4331, val_loss: 1.6411, val_acc: 0.4096\n",
      "Epoch [9], train_loss: 1.3889, val_loss: 1.4673, val_acc: 0.4536\n",
      "Epoch [10], train_loss: 1.2849, val_loss: 1.7780, val_acc: 0.3939\n",
      "Epoch [11], train_loss: 1.2600, val_loss: 1.4468, val_acc: 0.4748\n",
      "Epoch [12], train_loss: 1.1316, val_loss: 1.4625, val_acc: 0.4862\n",
      "Epoch [13], train_loss: 1.0564, val_loss: 1.6385, val_acc: 0.4588\n",
      "Epoch [14], train_loss: 1.0324, val_loss: 1.4426, val_acc: 0.5137\n",
      "   class  Test_Accuracy  Entropy_difference\n",
      "0      0       0.568486            0.005740\n",
      "1      1       0.600161            0.007813\n",
      "2      2       0.321668            0.002601\n",
      "3      3       0.389821            0.022687\n",
      "4      4       0.285915            0.004900\n",
      "5      5       0.455595            0.012550\n",
      "6      6       0.610604            0.002708\n",
      "7      7       0.550781            0.003968\n",
      "8      8       0.754262            0.018144\n",
      "9      9       0.528171            0.003306\n",
      "Epoch [0], train_loss: 2.2291, val_loss: 2.0609, val_acc: 0.2024\n",
      "Epoch [1], train_loss: 1.9578, val_loss: 1.9114, val_acc: 0.2733\n",
      "Epoch [2], train_loss: 1.8314, val_loss: 1.9724, val_acc: 0.2595\n",
      "Epoch [3], train_loss: 1.7722, val_loss: 2.0794, val_acc: 0.2737\n",
      "Epoch [4], train_loss: 1.7102, val_loss: 1.7199, val_acc: 0.3389\n",
      "Epoch [5], train_loss: 1.6123, val_loss: 1.5882, val_acc: 0.3869\n",
      "Epoch [6], train_loss: 1.5566, val_loss: 1.8560, val_acc: 0.3352\n",
      "Epoch [7], train_loss: 1.4913, val_loss: 1.9306, val_acc: 0.3496\n",
      "Epoch [8], train_loss: 1.4777, val_loss: 1.5023, val_acc: 0.4232\n",
      "Epoch [9], train_loss: 1.3487, val_loss: 1.5396, val_acc: 0.4416\n",
      "Epoch [10], train_loss: 1.2854, val_loss: 1.4643, val_acc: 0.4713\n",
      "Epoch [11], train_loss: 1.2272, val_loss: 1.4394, val_acc: 0.4832\n",
      "Epoch [12], train_loss: 1.1712, val_loss: 1.3302, val_acc: 0.5192\n",
      "Epoch [13], train_loss: 1.1468, val_loss: 1.3239, val_acc: 0.5201\n",
      "Epoch [14], train_loss: 1.0126, val_loss: 1.3763, val_acc: 0.5276\n",
      "   class  Test_Accuracy  Entropy_difference\n",
      "0      0       0.571783            0.007414\n",
      "1      1       0.674322            0.006112\n",
      "2      2       0.210443            0.010513\n",
      "3      3       0.222691            0.022895\n",
      "4      4       0.515970            0.021176\n",
      "5      5       0.488051            0.012604\n",
      "6      6       0.819405            0.012962\n",
      "7      7       0.537063            0.007431\n",
      "8      8       0.607698            0.006666\n",
      "9      9       0.635271            0.001314\n",
      "Epoch [0], train_loss: 2.2194, val_loss: 2.0841, val_acc: 0.2378\n",
      "Epoch [1], train_loss: 2.0466, val_loss: 1.9792, val_acc: 0.2730\n",
      "Epoch [2], train_loss: 1.9245, val_loss: 1.8368, val_acc: 0.3136\n",
      "Epoch [3], train_loss: 1.8123, val_loss: 1.8026, val_acc: 0.3193\n",
      "Epoch [4], train_loss: 1.7449, val_loss: 1.7879, val_acc: 0.3349\n",
      "Epoch [5], train_loss: 1.6388, val_loss: 1.7129, val_acc: 0.3691\n",
      "Epoch [6], train_loss: 1.5644, val_loss: 1.6426, val_acc: 0.4089\n",
      "Epoch [7], train_loss: 1.5032, val_loss: 1.8377, val_acc: 0.3679\n",
      "Epoch [8], train_loss: 1.4394, val_loss: 1.5165, val_acc: 0.4498\n",
      "Epoch [9], train_loss: 1.3590, val_loss: 1.5098, val_acc: 0.4381\n",
      "Epoch [10], train_loss: 1.2575, val_loss: 1.5268, val_acc: 0.4563\n",
      "Epoch [11], train_loss: 1.1568, val_loss: 1.4962, val_acc: 0.4855\n",
      "Epoch [12], train_loss: 1.0382, val_loss: 1.5325, val_acc: 0.4995\n",
      "Epoch [13], train_loss: 0.9916, val_loss: 1.5315, val_acc: 0.4932\n",
      "Epoch [14], train_loss: 0.8750, val_loss: 1.5916, val_acc: 0.4954\n",
      "   class  Test_Accuracy  Entropy_difference\n",
      "0      0       0.421369            0.000238\n",
      "1      1       0.570738            0.013335\n",
      "2      2       0.468566            0.016573\n",
      "3      3       0.425712            0.012025\n",
      "4      4       0.234743            0.009782\n",
      "5      5       0.463798            0.024369\n",
      "6      6       0.598093            0.013906\n",
      "7      7       0.608881            0.003379\n",
      "8      8       0.585719            0.004871\n",
      "9      9       0.577309            0.009123\n",
      "Epoch [0], train_loss: 2.3046, val_loss: 2.3038, val_acc: 0.1030\n",
      "Epoch [1], train_loss: 2.2085, val_loss: 2.0556, val_acc: 0.2340\n",
      "Epoch [2], train_loss: 2.0256, val_loss: 1.9211, val_acc: 0.2977\n",
      "Epoch [3], train_loss: 1.8639, val_loss: 1.8299, val_acc: 0.3174\n",
      "Epoch [4], train_loss: 1.7781, val_loss: 1.8564, val_acc: 0.3241\n",
      "Epoch [5], train_loss: 1.6683, val_loss: 1.6997, val_acc: 0.3694\n",
      "Epoch [6], train_loss: 1.6035, val_loss: 1.5880, val_acc: 0.4013\n",
      "Epoch [7], train_loss: 1.4834, val_loss: 1.5804, val_acc: 0.4301\n",
      "Epoch [8], train_loss: 1.4091, val_loss: 1.4999, val_acc: 0.4572\n",
      "Epoch [9], train_loss: 1.3395, val_loss: 1.5089, val_acc: 0.4652\n",
      "Epoch [10], train_loss: 1.2205, val_loss: 1.4863, val_acc: 0.4733\n",
      "Epoch [11], train_loss: 1.0847, val_loss: 1.5265, val_acc: 0.4707\n",
      "Epoch [12], train_loss: 1.0276, val_loss: 1.5414, val_acc: 0.4968\n",
      "Epoch [13], train_loss: 0.8646, val_loss: 1.5969, val_acc: 0.5193\n",
      "Epoch [14], train_loss: 0.7334, val_loss: 1.6604, val_acc: 0.5016\n",
      "   class  Test_Accuracy  Entropy_difference\n",
      "0      0       0.444922            0.016073\n",
      "1      1       0.565223            0.018206\n",
      "2      2       0.465005            0.005244\n",
      "3      3       0.353998            0.025635\n",
      "4      4       0.293049            0.035653\n",
      "5      5       0.509593            0.001449\n",
      "6      6       0.523231            0.004660\n",
      "7      7       0.541797            0.014113\n",
      "8      8       0.749931            0.008137\n",
      "9      9       0.585524            0.004532\n",
      "Epoch [0], train_loss: 2.2816, val_loss: 2.1514, val_acc: 0.1842\n",
      "Epoch [1], train_loss: 2.0696, val_loss: 2.0058, val_acc: 0.2563\n",
      "Epoch [2], train_loss: 1.9099, val_loss: 1.9230, val_acc: 0.2911\n",
      "Epoch [3], train_loss: 1.8137, val_loss: 1.7561, val_acc: 0.3424\n",
      "Epoch [4], train_loss: 1.7233, val_loss: 1.7323, val_acc: 0.3540\n",
      "Epoch [5], train_loss: 1.6131, val_loss: 1.6668, val_acc: 0.3851\n",
      "Epoch [6], train_loss: 1.5798, val_loss: 1.7585, val_acc: 0.3693\n",
      "Epoch [7], train_loss: 1.5220, val_loss: 1.5379, val_acc: 0.4278\n",
      "Epoch [8], train_loss: 1.3824, val_loss: 1.5016, val_acc: 0.4389\n",
      "Epoch [9], train_loss: 1.3069, val_loss: 1.5147, val_acc: 0.4500\n",
      "Epoch [10], train_loss: 1.2635, val_loss: 1.5062, val_acc: 0.4613\n",
      "Epoch [11], train_loss: 1.1646, val_loss: 1.5512, val_acc: 0.4730\n",
      "Epoch [12], train_loss: 1.0392, val_loss: 1.4501, val_acc: 0.4922\n",
      "Epoch [13], train_loss: 0.9148, val_loss: 1.4525, val_acc: 0.5132\n",
      "Epoch [14], train_loss: 0.7744, val_loss: 1.4577, val_acc: 0.5273\n",
      "   class  Test_Accuracy  Entropy_difference\n",
      "0      0       0.451677            0.004687\n",
      "1      1       0.729412            0.013111\n",
      "2      2       0.359226            0.008857\n",
      "3      3       0.316567            0.020229\n",
      "4      4       0.549391            0.004643\n",
      "5      5       0.376700            0.000858\n",
      "6      6       0.507744            0.007987\n",
      "7      7       0.603608            0.005174\n",
      "8      8       0.748552            0.002708\n",
      "9      9       0.659605            0.001825\n",
      "Epoch [0], train_loss: 2.2688, val_loss: 2.1256, val_acc: 0.2171\n",
      "Epoch [1], train_loss: 2.0545, val_loss: 2.0310, val_acc: 0.2303\n",
      "Epoch [2], train_loss: 1.9748, val_loss: 1.9421, val_acc: 0.2907\n",
      "Epoch [3], train_loss: 1.8919, val_loss: 1.8581, val_acc: 0.3129\n",
      "Epoch [4], train_loss: 1.7888, val_loss: 1.8039, val_acc: 0.3336\n",
      "Epoch [5], train_loss: 1.7569, val_loss: 1.7940, val_acc: 0.3461\n",
      "Epoch [6], train_loss: 1.6707, val_loss: 1.7064, val_acc: 0.3633\n",
      "Epoch [7], train_loss: 1.5891, val_loss: 1.6088, val_acc: 0.4213\n",
      "Epoch [8], train_loss: 1.5234, val_loss: 1.7349, val_acc: 0.3977\n",
      "Epoch [9], train_loss: 1.4895, val_loss: 1.5332, val_acc: 0.4577\n",
      "Epoch [10], train_loss: 1.3630, val_loss: 1.4831, val_acc: 0.4627\n",
      "Epoch [11], train_loss: 1.2930, val_loss: 1.4462, val_acc: 0.4871\n",
      "Epoch [12], train_loss: 1.2215, val_loss: 1.5380, val_acc: 0.4607\n",
      "Epoch [13], train_loss: 1.1335, val_loss: 1.4197, val_acc: 0.5028\n",
      "Epoch [14], train_loss: 1.0363, val_loss: 1.3707, val_acc: 0.5248\n",
      "   class  Test_Accuracy  Entropy_difference\n",
      "0      0       0.622564            0.022657\n",
      "1      1       0.675528            0.009906\n",
      "2      2       0.289798            0.005144\n",
      "3      3       0.259789            0.026417\n",
      "4      4       0.491935            0.007007\n",
      "5      5       0.509076            0.022349\n",
      "6      6       0.626517            0.014322\n",
      "7      7       0.626804            0.004591\n",
      "8      8       0.566602            0.008757\n",
      "9      9       0.607778            0.024109\n",
      "Epoch [0], train_loss: 2.3020, val_loss: 2.3030, val_acc: 0.1115\n",
      "Epoch [1], train_loss: 2.2040, val_loss: 2.2188, val_acc: 0.1441\n",
      "Epoch [2], train_loss: 2.0817, val_loss: 2.2123, val_acc: 0.1901\n",
      "Epoch [3], train_loss: 2.0415, val_loss: 1.9537, val_acc: 0.2644\n",
      "Epoch [4], train_loss: 1.8705, val_loss: 1.9743, val_acc: 0.2932\n",
      "Epoch [5], train_loss: 1.8043, val_loss: 1.7857, val_acc: 0.3418\n",
      "Epoch [6], train_loss: 1.7383, val_loss: 1.7845, val_acc: 0.3264\n",
      "Epoch [7], train_loss: 1.6258, val_loss: 1.6020, val_acc: 0.3947\n",
      "Epoch [8], train_loss: 1.5546, val_loss: 1.7251, val_acc: 0.3739\n",
      "Epoch [9], train_loss: 1.4903, val_loss: 1.5072, val_acc: 0.4328\n",
      "Epoch [10], train_loss: 1.4554, val_loss: 1.5247, val_acc: 0.4351\n",
      "Epoch [11], train_loss: 1.3621, val_loss: 1.4719, val_acc: 0.4497\n",
      "Epoch [12], train_loss: 1.3221, val_loss: 1.4518, val_acc: 0.4643\n",
      "Epoch [13], train_loss: 1.2461, val_loss: 1.4144, val_acc: 0.4865\n",
      "Epoch [14], train_loss: 1.1879, val_loss: 1.3779, val_acc: 0.5110\n",
      "   class  Test_Accuracy  Entropy_difference\n",
      "0      0       0.641808            0.004180\n",
      "1      1       0.760742            0.018097\n",
      "2      2       0.287799            0.001948\n",
      "3      3       0.387305            0.014185\n",
      "4      4       0.251264            0.011313\n",
      "5      5       0.436156            0.017922\n",
      "6      6       0.528171            0.017081\n",
      "7      7       0.614832            0.011740\n",
      "8      8       0.661535            0.006214\n",
      "9      9       0.545979            0.000457\n",
      "Epoch [0], train_loss: 2.3051, val_loss: 2.3022, val_acc: 0.1074\n",
      "Epoch [1], train_loss: 2.1875, val_loss: 2.0884, val_acc: 0.2148\n",
      "Epoch [2], train_loss: 2.0110, val_loss: 2.1197, val_acc: 0.2249\n",
      "Epoch [3], train_loss: 1.8950, val_loss: 1.8171, val_acc: 0.3083\n",
      "Epoch [4], train_loss: 1.7354, val_loss: 1.8716, val_acc: 0.3104\n",
      "Epoch [5], train_loss: 1.7172, val_loss: 1.7247, val_acc: 0.3659\n",
      "Epoch [6], train_loss: 1.6849, val_loss: 1.6269, val_acc: 0.4009\n",
      "Epoch [7], train_loss: 1.5282, val_loss: 1.6901, val_acc: 0.3924\n",
      "Epoch [8], train_loss: 1.4874, val_loss: 1.4971, val_acc: 0.4526\n",
      "Epoch [9], train_loss: 1.3812, val_loss: 1.4840, val_acc: 0.4436\n",
      "Epoch [10], train_loss: 1.3937, val_loss: 1.4241, val_acc: 0.4838\n",
      "Epoch [11], train_loss: 1.2014, val_loss: 1.5568, val_acc: 0.4802\n",
      "Epoch [12], train_loss: 1.1479, val_loss: 1.5711, val_acc: 0.4691\n",
      "Epoch [13], train_loss: 1.0515, val_loss: 1.4594, val_acc: 0.5102\n",
      "Epoch [14], train_loss: 0.8875, val_loss: 1.6763, val_acc: 0.4800\n",
      "   class  Test_Accuracy  Entropy_difference\n",
      "0      0       0.587397            0.005915\n",
      "1      1       0.640211            0.019782\n",
      "2      2       0.327999            0.013751\n",
      "3      3       0.445347            0.018563\n",
      "4      4       0.222737            0.023048\n",
      "5      5       0.504343            0.009057\n",
      "6      6       0.167532            0.001437\n",
      "7      7       0.613350            0.005258\n",
      "8      8       0.754182            0.006227\n",
      "9      9       0.523277            0.009566\n",
      "Epoch [0], train_loss: 2.3056, val_loss: 2.3024, val_acc: 0.1097\n",
      "Epoch [1], train_loss: 2.2604, val_loss: 2.4027, val_acc: 0.1727\n",
      "Epoch [2], train_loss: 2.1039, val_loss: 2.0013, val_acc: 0.2380\n",
      "Epoch [3], train_loss: 1.9209, val_loss: 1.9280, val_acc: 0.2587\n",
      "Epoch [4], train_loss: 1.8585, val_loss: 1.8354, val_acc: 0.2933\n",
      "Epoch [5], train_loss: 1.7648, val_loss: 1.8446, val_acc: 0.3128\n",
      "Epoch [6], train_loss: 1.7794, val_loss: 1.7681, val_acc: 0.3156\n",
      "Epoch [7], train_loss: 1.6822, val_loss: 1.6958, val_acc: 0.3518\n",
      "Epoch [8], train_loss: 1.6161, val_loss: 1.8464, val_acc: 0.3242\n",
      "Epoch [9], train_loss: 1.5911, val_loss: 1.6950, val_acc: 0.3743\n",
      "Epoch [10], train_loss: 1.5179, val_loss: 1.5960, val_acc: 0.4087\n",
      "Epoch [11], train_loss: 1.4557, val_loss: 1.6634, val_acc: 0.3802\n",
      "Epoch [12], train_loss: 1.4633, val_loss: 1.4936, val_acc: 0.4337\n",
      "Epoch [13], train_loss: 1.3758, val_loss: 1.4306, val_acc: 0.4665\n",
      "Epoch [14], train_loss: 1.3106, val_loss: 1.4488, val_acc: 0.4616\n",
      "   class  Test_Accuracy  Entropy_difference\n",
      "0      0       0.592233            0.009516\n",
      "1      1       0.638063            0.015124\n",
      "2      2       0.419508            0.000803\n",
      "3      3       0.157790            0.022485\n",
      "4      4       0.347748            0.004073\n",
      "5      5       0.493244            0.016783\n",
      "6      6       0.486811            0.009440\n",
      "7      7       0.584903            0.004786\n",
      "8      8       0.539740            0.003243\n",
      "9      9       0.396703            0.013889\n",
      "Epoch [0], train_loss: 2.3072, val_loss: 2.2308, val_acc: 0.1711\n",
      "Epoch [1], train_loss: 2.2688, val_loss: 2.1392, val_acc: 0.1917\n",
      "Epoch [2], train_loss: 2.0789, val_loss: 2.0144, val_acc: 0.2488\n",
      "Epoch [3], train_loss: 1.9383, val_loss: 1.9608, val_acc: 0.2521\n",
      "Epoch [4], train_loss: 1.8562, val_loss: 1.8677, val_acc: 0.2951\n",
      "Epoch [5], train_loss: 1.7686, val_loss: 1.7806, val_acc: 0.3182\n",
      "Epoch [6], train_loss: 1.6904, val_loss: 1.7216, val_acc: 0.3574\n",
      "Epoch [7], train_loss: 1.6141, val_loss: 1.7017, val_acc: 0.3675\n",
      "Epoch [8], train_loss: 1.5349, val_loss: 1.5794, val_acc: 0.4043\n",
      "Epoch [9], train_loss: 1.4500, val_loss: 1.5576, val_acc: 0.4295\n",
      "Epoch [10], train_loss: 1.3957, val_loss: 1.4657, val_acc: 0.4598\n",
      "Epoch [11], train_loss: 1.3259, val_loss: 1.5254, val_acc: 0.4436\n",
      "Epoch [12], train_loss: 1.2413, val_loss: 1.4412, val_acc: 0.4770\n",
      "Epoch [13], train_loss: 1.1574, val_loss: 1.4176, val_acc: 0.5037\n",
      "Epoch [14], train_loss: 1.0660, val_loss: 1.3816, val_acc: 0.5105\n",
      "   class  Test_Accuracy  Entropy_difference\n",
      "0      0       0.618727            0.021163\n",
      "1      1       0.636374            0.003015\n",
      "2      2       0.413580            0.004657\n",
      "3      3       0.344830            0.001691\n",
      "4      4       0.296036            0.007257\n",
      "5      5       0.468107            0.007325\n",
      "6      6       0.601298            0.015795\n",
      "7      7       0.534984            0.000649\n",
      "8      8       0.695703            0.004589\n",
      "9      9       0.629768            0.017176\n",
      "Epoch [0], train_loss: 2.2791, val_loss: 2.1145, val_acc: 0.1896\n",
      "Epoch [1], train_loss: 2.0873, val_loss: 2.0031, val_acc: 0.2395\n",
      "Epoch [2], train_loss: 1.9569, val_loss: 1.9897, val_acc: 0.2642\n",
      "Epoch [3], train_loss: 1.8592, val_loss: 1.9084, val_acc: 0.2841\n",
      "Epoch [4], train_loss: 1.7947, val_loss: 1.7360, val_acc: 0.3441\n",
      "Epoch [5], train_loss: 1.6905, val_loss: 1.7716, val_acc: 0.3465\n",
      "Epoch [6], train_loss: 1.6160, val_loss: 1.6946, val_acc: 0.3605\n",
      "Epoch [7], train_loss: 1.5474, val_loss: 1.5534, val_acc: 0.4239\n",
      "Epoch [8], train_loss: 1.5212, val_loss: 1.4828, val_acc: 0.4624\n",
      "Epoch [9], train_loss: 1.4059, val_loss: 1.7119, val_acc: 0.3553\n",
      "Epoch [10], train_loss: 1.4201, val_loss: 1.4594, val_acc: 0.4725\n",
      "Epoch [11], train_loss: 1.2604, val_loss: 1.4177, val_acc: 0.4787\n",
      "Epoch [12], train_loss: 1.2107, val_loss: 1.4491, val_acc: 0.4945\n",
      "Epoch [13], train_loss: 1.1456, val_loss: 1.4261, val_acc: 0.5072\n",
      "Epoch [14], train_loss: 1.1048, val_loss: 1.3219, val_acc: 0.5464\n",
      "   class  Test_Accuracy  Entropy_difference\n",
      "0      0       0.498518            0.004596\n",
      "1      1       0.755204            0.001737\n",
      "2      2       0.306916            0.009633\n",
      "3      3       0.322599            0.001192\n",
      "4      4       0.480584            0.022871\n",
      "5      5       0.382571            0.008064\n",
      "6      6       0.747541            0.000414\n",
      "7      7       0.538189            0.009129\n",
      "8      8       0.794497            0.011811\n",
      "9      9       0.562856            0.004009\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "fig, ax = plt.subplots(facecolor='lightgrey')\n",
    "for i in range(15):\n",
    "    subsample_500 = select_subsample(training_data_by_class)\n",
    "    subset_feature = {category: [] for category in subsample_500}\n",
    "\n",
    "    for category in subsample_500:\n",
    "        for img, label in subsample_500[category]:\n",
    "            output = modelCNN(to_device(img.unsqueeze(0), device))\n",
    "            subset_feature[label].append(features['18'])\n",
    "    for label in subset_feature:\n",
    "        subset_feature[label] = torch.cat(subset_feature[label], dim = 0).T \n",
    "    subset_singular_vector = {label: torch.svd(subset_feature[label])[1] for label in subset_feature}\n",
    "    # Here, we will compute the entropy value of each subset for each class\n",
    "    subset_entropy = {label: BSIE(subset_singular_vector[label]).item() for label in subset_singular_vector}\n",
    "\n",
    "\n",
    "    # Then we compute how much the subset entropy value deviates from the whole (training) set entropy value for each class\n",
    "    # If, for example, the class 3 subset entropy value is close to the whole training set entropy value of class 3, then it means\n",
    "    # the data structure of this subset is similar to the data structure of the whole class 3, so if this subset is a part of the \n",
    "    # whole training set, then the CNN trained on this training set is expected to perform well in classify the training data in class 3.\n",
    "    # Furthermore, because of our assumption that the test set of class 3 shares a similar data structure as the data structure of the \n",
    "    # training set of class 3, the CNN model might also perform well on the test set of class 3. \n",
    "\n",
    "\n",
    "    entropy_diff = {label: np.abs(entropy[label] - subset_entropy[label])/entropy[label] for label in entropy}\n",
    "    cifar10sub = ConcatDataset([subsample_500[class_name] for class_name in subsample_500])\n",
    "    cifar10sub_loader = DataLoader(cifar10sub, batch_size = batch_size, shuffle = True, pin_memory = True)\n",
    "    cifar10sub_train_loader = DeviceDataLoader(cifar10sub_loader, device)\n",
    "\n",
    "\n",
    "    val_dl = DataLoader(val_ds, batch_size*2, num_workers=4, pin_memory=True)\n",
    "    \n",
    "    model = to_device(Cifar10CnnModel(), device)\n",
    "    history = fit(num_epochs, lr, model, cifar10sub_train_loader, val_dl, opt_func)\n",
    "\n",
    "\n",
    "    # We evaluate the CNN trained with combined subsets from each class on the training set of each class\n",
    "\n",
    "    train_accuracy_by_class = {label: [] for label in training_data_by_class}\n",
    "\n",
    "    for label in training_data_by_class:\n",
    "        train_data = training_data_by_class[label]\n",
    "        train_data_loader = DeviceDataLoader(DataLoader(train_data, batch_size*2), device)\n",
    "        result = evaluate(model, train_data_loader)\n",
    "        result\n",
    "        train_accuracy_by_class[label] = result['val_acc']\n",
    "\n",
    "    df1 = pd.DataFrame(list(train_accuracy_by_class.items()), columns=['class', 'Test_Accuracy']) # training set accuracy by class of this submodel\n",
    "\n",
    "    \n",
    "    df2 = pd.DataFrame(list(entropy_diff.items()), columns=['class', 'Entropy_difference'])\n",
    "    merged_df = pd.merge(df1, df2, on='class')\n",
    "    print(merged_df)\n",
    "    plt.scatter(data=merged_df, x='Entropy_difference', y='Test_Accuracy', color = 'brown')\n",
    "    fig.canvas.draw()\n",
    "    fig.canvas.flush_events()\n",
    "    time.sleep(0.1)\n",
    "\n",
    "plt.xlabel('Entropy Difference')\n",
    "plt.ylabel('Test Accuracy (by class)')   \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not finished yet, will update later this week. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "fig, ax1 = plt.subplots(facecolor='lightgrey')\n",
    "for i in range(2):\n",
    "    y = np.random.rand(4)\n",
    "    x = np.random.rand(4)\n",
    "    df = pd.DataFrame({\"xc\": x, \"yc\": y})\n",
    "    \n",
    "    plt.scatter(x = \"xc\", y = \"yc\", data = df, color = 'brown')\n",
    "    fig.canvas.draw()\n",
    "    fig.canvas.flush_events()\n",
    "    time.sleep(0.1)\n",
    "    \n",
    "plt.xlabel('X axis')\n",
    "plt.ylabel('Y axis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
